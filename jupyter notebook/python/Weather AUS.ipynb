import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from scipy import stats


# Load the dataset
data = pd.read_csv('D:\#NEWDOWNLOADS\weatherAUS.csv')

# Data Exploration and Visualization
# 1. Understanding the data
print(data.head())
print(data.info())
print(data.describe())

df = pd.read_csv('D:\#NEWDOWNLOADS\weatherAUS.csv')
df.info()

df.drop(columns=['Evaporation','Sunshine','Cloud9am','Cloud3pm'],axis =1, inplace = True)


# Load the dataset
data = pd.read_csv('D:/#NEWDOWNLOADS/weatherAUS.csv')

# Select numerical columns
cols = data.select_dtypes(include=['int64', 'float64']).columns.tolist()

# Define a list of colors
colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange', 'purple', 'brown']

# Plot distribution and Q-Q plot for each numerical column with various colors
for col in cols:
    color = np.random.choice(colors)  # Randomly choose a color
    plt.figure(figsize=(15, 5))

    plt.subplot(121)
    sns.histplot(data[col], kde=True, color=color)
    plt.title(f'Distribution of {col}')

    plt.subplot(122)
    stats.probplot(data[col], dist="norm", plot=plt)
    plt.title(f'Q-Q Plot of {col}')

    plt.show()

# Load the DataFrame (replace this with your actual DataFrame loading code)
df = pd.read_csv('D:/#NEWDOWNLOADS/weatherAUS.csv')

# Select numerical columns
numeric_df = df.select_dtypes(include=['number'])

# Calculate correlation matrix
correlation_matrix = numeric_df.corr()

plt.figure(figsize=(12, 8))

# Change the color palette
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)

plt.title('Correlation Matrix')
plt.show()

# Load data (replace with your path)
data = pd.read_csv('D:\#NEWDOWNLOADS\weatherAUS.csv')
# Split features (X) and target (Y)
X = df.drop('Churn', axis=1)
Y = df['Churn']

# Split data (train/test)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Preprocessing pipeline (one-liner)
preprocessor = ColumnTransformer([
    ('num', Pipeline([('imp', IterativeImputer()), ('scaler', StandardScaler())]), X_train.select_dtypes(include=['int64', 'float64', 'int32']).columns),
    ('cat', Pipeline([('imp', SimpleImputer(strategy='most_frequent')), ('enc', OneHotEncoder(handle_unknown='ignore', sparse=False))]), X_train.select_dtypes(include='object').columns)
])

# Machine learning pipeline (one-liner)
pipeline = Pipeline([('preprocessor', preprocessor), ('clf', RandomForestClassifier(n_estimators=100, random_state=42))])

# Train model
pipeline.fit(X_train, Y_train)

# Predict on test set
y_pred = pipeline.predict(X_test)

# Evaluate model (one-liners)
accuracy = accuracy_score(Y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')
print("Classification Report:\n", classification_report(Y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(Y_test, y_pred))
